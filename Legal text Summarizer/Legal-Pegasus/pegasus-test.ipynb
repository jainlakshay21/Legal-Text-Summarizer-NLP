{"cells":[{"cell_type":"markdown","id":"8a842a0a","metadata":{"id":"8a842a0a"},"source":["### Script to generate summaries using chunking based Pegasus approach"]},{"cell_type":"code","execution_count":56,"id":"cb972436","metadata":{"id":"cb972436"},"outputs":[],"source":["dataset = \"IN-Abs\" # Options: IN - IN-Abs, UK-UK-Abs, N2-IN-Ext\n","output_path = \"/Users/lakke21/Downloads/summarization-aacl/abstractive/Legal-Pegasus/output\"\n"]},{"cell_type":"code","execution_count":57,"id":"1a83915a","metadata":{"id":"1a83915a"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import sys\n","sys.path.insert(0, '../')\n","from utilities import *\n","import os\n","import nltk"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["def get_root_path1():\n","    '''\n","    function to get root path of dataset\n","\n","    change the path variable to the path of the dataset\n","    '''\n","    path = \"/Users/lakke21/Downloads/dataset\"\n","    return path"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["def get_summary_data1(dataset, train):\n","    '''\n","    function to get names, documents, and summaries\n","\n","    change the path variable to the path of the dataset\n","    \n","    if dataset == \"N2\":\n","        path = get_root_path1() + '/N2/Full-Text/India'\n","        all_files = glob.glob(path + \"/*.txt\")\n","\n","        data_source = []\n","        names = []\n","        for filename in all_files:\n","            with open(filename, 'r') as f: \n","                p = filename.rfind(\"/\")\n","#                 print(filename[p+1:])\n","                names.append(filename[p+1:])\n","                a = f.read()\n","                data_source.append(a)\n","        return names, data_source, []'''\n","    \n","    path = get_root_path1() + '/' + dataset + '/' + train + '-data/judgement'\n","    all_files = glob.glob(path + \"/*.txt\")\n","    data_source = []\n","    names = []\n","    for filename in all_files:\n","        with open(filename, 'r') as f:\n","            p = filename.rfind(\"/\")\n","            names.append(filename[p+1:])\n","            a = f.read()\n","            data_source.append(a)\n","    path = get_root_path1() + '/' + dataset + '/' + train + '-data/summary'\n","    all_files = glob.glob(path + \"/*.txt\")\n","    data_summary = []\n","    for filename in all_files:\n","        with open(filename, 'r') as f: \n","            a = f.read()\n","            l = len(a)\n","            data_summary.append(a)\n","            \n","    return names, data_source, data_summary"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def get_req_len_dict1(dataset, istrain):\n","    '''\n","    function to required length data for each summary\n","\n","    change the path variable to the path to Summary_Length_India.txt/ Summary_Length_Uk.txt file\n","    '''\n","    \n","    '''if dataset == \"N2\":\n","        f = open(get_root_path1() + \"/N2/Summary_Length_India.txt\", \"r\")\n","        a = (f.read())\n","        a = a.split(\"\\n\")\n","        dict_names = {}\n","        for i in a:\n","            b = i.split(\"\t\")\n","            dict_names[b[0] + \".txt\"] = int(b[1])\n","        return dict_names'''\n","    \n","    f = open(get_root_path1() + \"/IN-Abs/test-data/stats-IN-test.txt\", \"r\")\n","    a = (f.read())\n","    a = a.split(\"\\n\")\n","    dict_names = {}\n","    for i in a:\n","        b = i.split(\"\t\")\n","        try:\n","            tp = int(b[2])\n","            dict_names[b[0]] = tp\n","        except:\n","            print(b)\n","    return dict_names  "]},{"cell_type":"code","execution_count":61,"id":"049e7a6f","metadata":{"id":"049e7a6f"},"outputs":[],"source":["if not os.path.exists(output_path):\n","    os.makedirs(output_path)"]},{"cell_type":"code","execution_count":62,"id":"0591966a","metadata":{"id":"0591966a"},"outputs":[{"name":"stdout","output_type":"stream","text":["100\n","100\n","100\n","['']\n"]}],"source":["#Reading the test documents\n","names, data_source, data_summary = get_summary_data1(dataset, \"test\")\n","print(len(names))\n","print(len(data_source))\n","print(len(data_summary))\n","len_dic = dict_names = get_req_len_dict1(dataset, \"test\")  "]},{"cell_type":"code","execution_count":63,"id":"14b68b70","metadata":{"id":"14b68b70"},"outputs":[],"source":["device = \"cpu\""]},{"cell_type":"code","execution_count":64,"id":"0596cefd","metadata":{"id":"0596cefd"},"outputs":[],"source":["# Loading Model and tokenizer\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments, PegasusTokenizerFast\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")  \n","model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\").to(device)\n","#model_path = '/Users/lakke21/Downloads/summarization-aacl/abstractive/Legal-Pegasus/ouput_model'  # Ensure this is the path where your model is saved\n","#model = PegasusForConditionalGeneration.from_pretrained(model_path)\n","#tokenizer = PegasusTokenizerFast.from_pretrained(model_path)\n"]},{"cell_type":"code","execution_count":65,"id":"49734483","metadata":{"id":"49734483"},"outputs":[],"source":["def summerize(text, max_len, min_len):\n","    '''\n","    Function to generate summary using Pegasus\n","    input:  nested_sentences - chunks\n","            max_l - Maximum length\n","            min_l - Minimum length\n","    output: document summary\n","    '''\n","    try:\n","        input_tokenized = tokenizer.encode(text, return_tensors='pt',max_length=512,truncation=True).to(device)\n","        summary_ids = model.generate(input_tokenized,\n","                                          num_beams=9,\n","                                          length_penalty=0.1,\n","                                          min_length=min_len,\n","                                          max_length=max_len,\n","                                    )\n","        summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n","        return summary\n","    except:\n","        return \"\""]},{"cell_type":"code","execution_count":66,"id":"e7f05633","metadata":{"id":"e7f05633"},"outputs":[],"source":["def summerize_doc(nested_sentences, p):\n","    '''\n","    Function to generate summary using chunking based Pegasus\n","    input:  nested_sentences - chunks\n","            p - Number of words in summaries per word in the document\n","    output: document summary\n","    '''\n","    device = 'cpu'\n","    result = []\n","    for nested in nested_sentences:\n","        l = int(p * len(nested.split(\" \")))\n","        max_len = l\n","        min_len = l-5\n","        result.append(summerize(nested, max_len, min_len))\n","    return result"]},{"cell_type":"code","execution_count":67,"id":"fd0385a1","metadata":{"id":"fd0385a1"},"outputs":[],"source":["'''done_files = glob.glob(output_path + \"*.txt\")\n","done_files = [i[i.rfind(\"/\")+1:] for i in done_files]'''\n","\n","new_output_path = \"/Users/lakke21/Downloads/summarization-aacl/abstractive/Legal-Pegasus/output\"\n","\n","# Ensure the new output directory exists\n","if not os.path.exists(new_output_path):\n","    os.makedirs(new_output_path)"]},{"cell_type":"code","execution_count":68,"id":"0da2186e","metadata":{"id":"0da2186e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0: 6728.txt - 830 : 436, 0.5253012048192771\n","403\n","403\n"]}],"source":["'''# main loop to generate and save summaries of each document in the test dataset\n","#for i in range(len(data_source)):\n","for i in range(1):\n","    done_files = glob.glob(output_path + \"*.txt\")\n","    done_files = [i[i.rfind(\"/\")+1:] for i in done_files]\n","    name = names[i]'''\n","for i in range(1):\n","    # Use the new output path for checking existing files\n","    done_files = glob.glob(os.path.join(new_output_path, \"*.txt\"))\n","    #done_files = [os.path.basename(f) for f in done_files]\n","    name = names[i]\n","    if name in done_files:continue\n","    doc = data_source[i]\n","    input_len = len(doc.split(\" \"))\n","    req_len = dict_names[name]\n","    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \", \")\n","    \n","    nested = nest_sentences(doc,512)\n","    p = float(req_len/input_len)\n","    print(p)\n","    abs_summ = summerize_doc(nested,p)\n","    abs_summ = \" \".join(abs_summ)\n","    print(len((abs_summ.split(\" \"))))\n","    \n","    if len(abs_summ.split(\" \")) > req_len:\n","        abs_summ = abs_summ.split(\" \")\n","        abs_summ = abs_summ[:req_len]\n","        abs_summ = \" \".join(abs_summ)\n","    print(len((abs_summ.split(\" \"))))\n","    summary_file_path = os.path.join(new_output_path, name)\n","    #path = new_output_path + name\n","    file = open(summary_file_path,'w')\n","    file.write(abs_summ)\n","    file.close()\n","#     break'''"]},{"cell_type":"code","execution_count":69,"id":"33df9665","metadata":{"id":"33df9665"},"outputs":[{"data":{"text/plain":["'import os\\nimport glob\\n\\n# Update this to your desired new output directory\\nnew_output_path = \"/Users/lakke21/Downloads/summarization-aacl/abstractive/Legal-Pegasus/output\"\\n\\n# Ensure the new output directory exists\\nif not os.path.exists(new_output_path):\\n    os.makedirs(new_output_path)\\n\\n# main loop to generate and save summaries of each document in the test dataset\\nfor i in range(1):\\n    # Use the new output path for checking existing files\\n    done_files = glob.glob(os.path.join(new_output_path, \"*.txt\"))\\n    done_files = [os.path.basename(f) for f in done_files]\\n    name = names[i]\\n\\n    print(f\"Checking if summary for {name} exists in the new location...\")\\n\\n    if name in done_files:\\n        print(f\"Summary for {name} already exists. Skipping...\")\\n        continue\\n    \\n    # ... (rest of your code for generating summary)\\n\\n    # Use the new output path for saving the summary\\n    summary_file_path = os.path.join(new_output_path, name)\\n\\n    print(f\"Saving summary for {name} at {summary_file_path}\")\\n\\n    with open(summary_file_path, \\'w\\') as file:\\n        file.write(abs_summ)\\n\\n    print(f\"Summary for {name} saved successfully.\")'"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["'''import os\n","import glob\n","\n","# Update this to your desired new output directory\n","new_output_path = \"/Users/lakke21/Downloads/summarization-aacl/abstractive/Legal-Pegasus/output\"\n","\n","# Ensure the new output directory exists\n","if not os.path.exists(new_output_path):\n","    os.makedirs(new_output_path)\n","\n","# main loop to generate and save summaries of each document in the test dataset\n","for i in range(1):\n","    # Use the new output path for checking existing files\n","    done_files = glob.glob(os.path.join(new_output_path, \"*.txt\"))\n","    done_files = [os.path.basename(f) for f in done_files]\n","    name = names[i]\n","\n","    print(f\"Checking if summary for {name} exists in the new location...\")\n","\n","    if name in done_files:\n","        print(f\"Summary for {name} already exists. Skipping...\")\n","        continue\n","    \n","    # ... (rest of your code for generating summary)\n","\n","    # Use the new output path for saving the summary\n","    summary_file_path = os.path.join(new_output_path, name)\n","\n","    print(f\"Saving summary for {name} at {summary_file_path}\")\n","\n","    with open(summary_file_path, 'w') as file:\n","        file.write(abs_summ)\n","\n","    print(f\"Summary for {name} saved successfully.\")'''\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"pegasus-test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":5}
